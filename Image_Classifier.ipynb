{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f913b7c3-fd18-4552-8787-47e68500ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim  as optim\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25218a6b-5e05-4158-b8cb-f7ec83cd9f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets,transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0154e674-eb3a-48d4-aaa1-b002962e44ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "\n",
    "training_datasets = datasets.CIFAR10(root=\"data\",train=True,download=True,transform=transformer)\n",
    "test_datasets = datasets.CIFAR10(root=\"data\",train=True,download=True,transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18e09b0f-2723-44ee-9b33-cfe70039897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loader = DataLoader(training_datasets,shuffle=True,batch_size=32)\n",
    "test_loader = DataLoader(test_datasets,shuffle=True,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22e5a75d-bdea-4d2b-8c93-732e4c66fce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1a5720b81d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709ce157-ed32-42aa-8e2e-bb209a92011d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features,label = training_datasets[0]\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "19d628a4-4c79-4957-a8bc-20aa672fde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]\t\t\t\t\t\t\t\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ee79d1b-4760-4c0c-a641-86f9927679bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNeuralNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3,12,5) #Creates a new layer\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.conv2 = nn.Conv2d(12,24,5)\n",
    "        self.fc1 = nn.Linear(24*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "\n",
    "    def forward(self,features):\n",
    "        features = self.pool(F.relu(self.conv1(features)))\n",
    "        features = self.pool(F.relu(self.conv2(features)))\n",
    "        features = torch.flatten(features,1)\n",
    "        features = F.relu(self.fc1(features))\n",
    "        features = F.relu(self.fc2(features))\n",
    "        features = self.fc3(features)\n",
    "        return features        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e31855d-4b7c-476e-a48d-93f5c0820374",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = MyNeuralNetwork()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(cnn_model.parameters(),lr=0.001,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ccd4114-7b68-4b3c-86c8-7445745e8952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING EPOCHS ... 0 ===\n",
      "Loss : 0.0012251514695961355\n",
      "=== TRAINING EPOCHS ... 1 ===\n",
      "Loss : 0.0008833401491454376\n",
      "=== TRAINING EPOCHS ... 2 ===\n",
      "Loss : 0.0007277329000081302\n",
      "=== TRAINING EPOCHS ... 3 ===\n",
      "Loss : 0.0008259520497142087\n",
      "=== TRAINING EPOCHS ... 4 ===\n",
      "Loss : 0.0012597491629826893\n",
      "=== TRAINING EPOCHS ... 5 ===\n",
      "Loss : 0.000615860091823839\n",
      "=== TRAINING EPOCHS ... 6 ===\n",
      "Loss : 0.0007993946911353601\n",
      "=== TRAINING EPOCHS ... 7 ===\n",
      "Loss : 0.0007135649178932664\n",
      "=== TRAINING EPOCHS ... 8 ===\n",
      "Loss : 0.00043288340419054183\n",
      "=== TRAINING EPOCHS ... 9 ===\n",
      "Loss : 0.0004912078266180409\n",
      "=== TRAINING EPOCHS ... 10 ===\n",
      "Loss : 0.0006737899719257806\n",
      "=== TRAINING EPOCHS ... 11 ===\n",
      "Loss : 0.0005184953516290802\n",
      "=== TRAINING EPOCHS ... 12 ===\n",
      "Loss : 0.0005247126537794039\n",
      "=== TRAINING EPOCHS ... 13 ===\n",
      "Loss : 0.0005364897383838148\n",
      "=== TRAINING EPOCHS ... 14 ===\n",
      "Loss : 0.0005307355830094331\n",
      "=== TRAINING EPOCHS ... 15 ===\n",
      "Loss : 0.0005099782940674805\n",
      "=== TRAINING EPOCHS ... 16 ===\n",
      "Loss : 0.0002942762158272439\n",
      "=== TRAINING EPOCHS ... 17 ===\n",
      "Loss : 0.0007195752626493507\n",
      "=== TRAINING EPOCHS ... 18 ===\n",
      "Loss : 0.0008097900767701601\n",
      "=== TRAINING EPOCHS ... 19 ===\n",
      "Loss : 0.00021573224284293478\n",
      "=== TRAINING EPOCHS ... 20 ===\n",
      "Loss : 0.00028869027292125897\n",
      "=== TRAINING EPOCHS ... 21 ===\n",
      "Loss : 0.00021435782761430406\n",
      "=== TRAINING EPOCHS ... 22 ===\n",
      "Loss : 0.00032742459729781\n",
      "=== TRAINING EPOCHS ... 23 ===\n",
      "Loss : 0.0005693714815458272\n",
      "=== TRAINING EPOCHS ... 24 ===\n",
      "Loss : 0.0007025750874710327\n",
      "=== TRAINING EPOCHS ... 25 ===\n",
      "Loss : 0.00041683896260618475\n",
      "=== TRAINING EPOCHS ... 26 ===\n",
      "Loss : 0.0004720949470729913\n",
      "=== TRAINING EPOCHS ... 27 ===\n",
      "Loss : 0.00034159788014563857\n",
      "=== TRAINING EPOCHS ... 28 ===\n",
      "Loss : 0.0003173185782942037\n",
      "=== TRAINING EPOCHS ... 29 ===\n",
      "Loss : 0.0005363493642971749\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    print(f\"=== TRAINING EPOCHS ... {epoch} ===\")\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i,data in enumerate(training_loader):\n",
    "        inputs,labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(inputs)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss =+ loss.item()\n",
    "        \n",
    "    print(f\"Loss : {running_loss/len(training_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "767757be-c81c-4226-be82-d7a3bbd3912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1a5720b81d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8b952ca-1d91-4033-9e0b-f9265dea8ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model.state_dict(),\"trained_neural.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "573f1724-5bdc-4ec8-ae1e-d44b49e06f21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model = MyNeuralNetwork()\n",
    "cnn_model.load_state_dict(torch.load(\"trained_neural.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa853385-239c-4119-9528-e2062f74db5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82f868fc-c838-4b91-b2bc-abcb0924cf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model : 84.76%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "cnn_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for datas,labels in test_loader:\n",
    "        datas,labels = datas.to(device), labels.to(device)\n",
    "        outputs = cnn_model(datas)\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    accuracy = 100* correct/total\n",
    "\n",
    "    print(f\"Accuracy of the model : {accuracy:.2f}%\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35bd49fe-35d7-4cfa-8077-651224b0c761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : airplane\n",
      "Item : 0\n",
      "Predicted Tensors of the Images : tensor([0])\n"
     ]
    }
   ],
   "source": [
    "new_transformer = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5]),\n",
    "])\n",
    "\n",
    "\n",
    "def Image_Loader (image_path): \n",
    "    image = Image.open(image_path)\n",
    "    image = new_transformer(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "my_input = Image_Loader(\"Golden+Retrievers+dans+pet+care.jpeg\")\n",
    "airplane_image = Image_Loader(\"images.jpg\")\n",
    "dog_image = Image_Loader(\"dog_2.jpg\")\n",
    "\n",
    "\n",
    "#prediction over here\n",
    "with torch.no_grad():\n",
    "    output = cnn_model(airplane_image)\n",
    "    _, predicted = torch.max(output,1)\n",
    "    print(f\"Prediction : {class_names[predicted.item()]}\")\n",
    "    print(f\"Item : {predicted.item()}\")\n",
    "    print(f\"Predicted Tensors of the Images : {predicted}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "efceec51-5458-4bd1-871a-8dd1e189dc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : dog\n"
     ]
    }
   ],
   "source": [
    "output = cnn_model(dog_image)\n",
    "_, predicted = torch.max(output,1)\n",
    "print(f\"Prediction : {class_names[predicted.item()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "88a6b134-37d0-4f33-8a31-58c8da92933f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4118, -0.3490, -0.2784,  ..., -0.2078, -0.1843, -0.1529],\n",
       "          [-0.4510, -0.4039, -0.3569,  ..., -0.2314, -0.2000, -0.1765],\n",
       "          [-0.4980, -0.4667, -0.4431,  ..., -0.2627, -0.2314, -0.2157],\n",
       "          ...,\n",
       "          [-0.1608, -0.2000, -0.2235,  ..., -0.1608, -0.2314, -0.3255],\n",
       "          [-0.1529, -0.1765, -0.2235,  ..., -0.4431, -0.4745, -0.5059],\n",
       "          [-0.6863, -0.6941, -0.7333,  ..., -0.2235, -0.4196, -0.3961]],\n",
       "\n",
       "         [[-0.6078, -0.5765, -0.5529,  ..., -0.4745, -0.4588, -0.4196],\n",
       "          [-0.6392, -0.6157, -0.6000,  ..., -0.4902, -0.4745, -0.4353],\n",
       "          [-0.6706, -0.6627, -0.6471,  ..., -0.5059, -0.4824, -0.4588],\n",
       "          ...,\n",
       "          [-0.3333, -0.3725, -0.3882,  ..., -0.3725, -0.4196, -0.5059],\n",
       "          [-0.3412, -0.3569, -0.3882,  ..., -0.5843, -0.6157, -0.6471],\n",
       "          [-0.7490, -0.7725, -0.8039,  ..., -0.4039, -0.5451, -0.5294]],\n",
       "\n",
       "         [[-0.7961, -0.7725, -0.7490,  ..., -0.6314, -0.6157, -0.5765],\n",
       "          [-0.8275, -0.8039, -0.7882,  ..., -0.6549, -0.6314, -0.6000],\n",
       "          [-0.8431, -0.8353, -0.8275,  ..., -0.6706, -0.6392, -0.6078],\n",
       "          ...,\n",
       "          [-0.3882, -0.4196, -0.4431,  ..., -0.4353, -0.4667, -0.5451],\n",
       "          [-0.4118, -0.4039, -0.4353,  ..., -0.6157, -0.6392, -0.6863],\n",
       "          [-0.8353, -0.8196, -0.8510,  ..., -0.4431, -0.5686, -0.5608]]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4305d3d3-a912-4816-98c5-7f3ca3c84935",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
